# distributted_distillation
This is a code for distributed distillation training.
Distillation would be a great way to enhance training performance and speed. That is the way to enhance the federal learning performance. 
